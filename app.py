
from dotenv import load_dotenv

load_dotenv()

import os
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate


# =========================
# ã‚³ã‚¢å‡¦ç†é–¢æ•°
# =========================
def run_llm(user_text: str, role_choice: str) -> str:
    """
    å¼•æ•°:
        user_text    : å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•ï¼‰
        role_choice  : ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®é¸æŠå€¤ï¼ˆ"A" or "B" ã‚’å«ã‚€æ–‡å­—åˆ—ã‚’æƒ³å®šï¼‰

    æˆ»ã‚Šå€¤:
        LLMã®å›ç­”ãƒ†ã‚­ã‚¹ãƒˆï¼ˆstrï¼‰
    """
    # é¸æŠã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    if str(role_choice).startswith("A"):
        system_message = (
            "ã‚ãªãŸã¯Aã®é ˜åŸŸã«è©³ã—ã„ã€å¥åº·ã®å°‚é–€å®¶ã€ã§ã™ã€‚"
            "æ—¥æœ¬èªã§ã€ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã«åŸºã¥ã„ãŸã‚ã‹ã‚Šã‚„ã™ã„åŠ©è¨€ã‚’ä¸ãˆã¦ãã ã•ã„ã€‚"
            "è¨ºæ–­è¡Œç‚ºã¯é¿ã‘ã€ä¸€èˆ¬çš„ãªå¥åº·ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã¨ã‚»ãƒ«ãƒ•ã‚±ã‚¢ã€å—è¨ºã®ç›®å®‰ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚"
        )
    else:
        system_message = (
            "ã‚ãªãŸã¯Bã®é ˜åŸŸã«è©³ã—ã„ã€æ•™è‚²ã®å°‚é–€å®¶ã€ã§ã™ã€‚"
            "æ—¥æœ¬èªã§ã€å­¦ç¿’è€…ã®ç†è§£ã‚’åŠ©ã‘ã‚‹æ§‹é€ åŒ–ã•ã‚ŒãŸèª¬æ˜ã¨ã€å¹´é½¢ã‚„ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸå®Ÿè·µçš„ã‚¹ãƒ†ãƒƒãƒ—ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"
            "æ ¹æ‹ ï¼ˆç†è«–ãƒ»ç ”ç©¶ãƒ»äº‹ä¾‹ï¼‰ã‚’çŸ­ãè£œè¶³ã—ã¦ãã ã•ã„ã€‚"
        )

    # ChatOpenAI ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    # OPENAI_API_KEY ã¯ç’°å¢ƒå¤‰æ•° or Streamlit Secrets ã§è¨­å®šã—ã¦ãŠã
    #   - Streamlit Cloud: [Project] â†’ [Settings] â†’ [Secrets] ã« OPENAI_API_KEY ã‚’ç™»éŒ²
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.2,
    )

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆé¸æŠãƒ­ãƒ¼ãƒ«ã«åˆã‚ã›ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ç”¨ï¼‰
    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_message),
            ("human", "{user_input}"),
        ]
    )

    # ãƒã‚§ãƒ¼ãƒ³ï¼ˆPrompt â†’ LLMï¼‰
    chain = prompt | llm

    # å®Ÿè¡Œ
    result = chain.invoke({"user_input": user_text})
    # result ã¯ BaseMessageã€‚é€šå¸¸ã¯ .content ã«ãƒ†ã‚­ã‚¹ãƒˆãŒå…¥ã‚‹
    return getattr(result, "content", str(result))


# =========================
# Streamlit UI
# =========================
st.set_page_config(page_title="LangChain Ã— LLM ãƒ‡ãƒ¢", page_icon="ğŸ¤–", layout="centered")
st.title("ğŸ¤– LangChain Ã— LLM ãƒ•ã‚©ãƒ¼ãƒ é€ä¿¡ãƒ‡ãƒ¢")

# æ¦‚è¦ã¨æ“ä½œæ–¹æ³•ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘èª¬æ˜ï¼‰
st.markdown(
    """
### ã“ã®ã‚¢ãƒ—ãƒªã«ã¤ã„ã¦
- 1ã¤ã®å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«è³ªå•ã‚„æ–‡ç« ã‚’å…¥åŠ›ã—ã€é€ä¿¡ã™ã‚‹ã¨ã€é¸æŠã—ãŸå°‚é–€å®¶ã®è¦–ç‚¹ã§LLMï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ãŒå›ç­”ã—ã¾ã™ã€‚  
- LangChain ã‚’ç”¨ã„ã¦ã€ãƒ•ã‚©ãƒ¼ãƒ ã®å…¥åŠ›ã‚’ãã®ã¾ã¾ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã—ã¦ LLM ã¸æ¸¡ã—ã¦ã„ã¾ã™ã€‚

### ä½¿ã„æ–¹
1. **å°‚é–€å®¶ã®ç¨®é¡** ã‚’ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‹ã‚‰é¸ã³ã¾ã™ï¼ˆA: å¥åº·ã®å°‚é–€å®¶ / B: æ•™è‚²ã®å°‚é–€å®¶ï¼‰ã€‚  
2. **å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ** ã«è³ªå•ã‚„æ–‡ç« ã‚’å…¥åŠ›ã—ã¾ã™ã€‚  
3. **é€ä¿¡** ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€LLM ã®å›ç­”ãŒç”»é¢ä¸‹ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

> â€» Streamlit Community Cloud ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹å ´åˆã¯ã€`runtime.txt` ã« `python-3.11` ã¨è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚  
> â€» APIã‚­ãƒ¼ï¼ˆ`OPENAI_API_KEY`ï¼‰ã¯ã€ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ Streamlit ã® Secrets ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚
"""
)

# APIã‚­ãƒ¼ç¢ºèªï¼ˆæœªè¨­å®šæ™‚ã¯è­¦å‘Šï¼‰
if not (os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", None)):
    st.warning("ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯ Secrets ã« OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å®Ÿè¡Œå‰ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")

# --- å°‚é–€å®¶ãƒ­ãƒ¼ãƒ«é¸æŠ ---
role_choice = st.radio(
    "LLMã®æŒ¯ã‚‹èˆã„ï¼ˆå°‚é–€å®¶ã®ç¨®é¡ï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
    options=["Aï¼ˆAã®é ˜åŸŸã®å¥åº·ã®å°‚é–€å®¶ï¼‰", "Bï¼ˆBã®é ˜åŸŸã®æ•™è‚²ã®å°‚é–€å®¶ï¼‰"],
    horizontal=True,
)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
with st.form("query_form"):
    user_text = st.text_area(
        "å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ï¼š",
        placeholder="ã“ã“ã«è³ªå•ã‚„æ–‡ç« ã‚’å…¥åŠ›ã—ã¦é€ä¿¡ã—ã¦ãã ã•ã„ã€‚",
        height=150,
    )
    submitted = st.form_submit_button("é€ä¿¡")

# é€ä¿¡æ™‚ã®å®Ÿè¡Œï¼ˆé–¢æ•° run_llm ã‚’åˆ©ç”¨ï¼‰
if submitted:
    if not user_text.strip():
        st.error("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("LLMã«å•ã„åˆã‚ã›ä¸­â€¦"):
            try:
                answer = run_llm(user_text=user_text, role_choice=role_choice)
                st.subheader("å›ç­”çµæœ")
                st.markdown(answer)
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
